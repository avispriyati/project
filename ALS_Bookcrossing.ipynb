{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yLrw29HALw0",
        "outputId": "50ee8ebe-db8a-4ca3-eac7-c75178dcee36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:3 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Get:6 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,244 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,986 kB]\n",
            "Fetched 5,482 kB in 4s (1,442 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "55 packages can be upgraded. Run 'apt list --upgradable' to see them.\n"
          ]
        }
      ],
      "source": [
        "! apt update"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3Riz5g990hW"
      },
      "outputs": [],
      "source": [
        "#Java JDK\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "#Downloading Spark\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.0.0/spark-3.0.0-bin-hadoop3.2.tgz\n",
        "#Unzipping the hadoop file\n",
        "!tar xf spark-3.0.0-bin-hadoop3.2.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xk5wePix94Ef",
        "outputId": "3d678fbb-90f3-44b6-d6ac-da71e843c2e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  book1M.zip\n",
            "   creating: book1M/\n",
            "  inflating: book1M/BX-Book-Ratings.csv  \n",
            "  inflating: book1M/BX-Books.csv     \n",
            "  inflating: book1M/BX-Users.csv     \n",
            "  inflating: book1M/explicit_ratings_books.csv  \n"
          ]
        }
      ],
      "source": [
        "#Unzip the file\n",
        "!unzip book1M.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xie483cW980m"
      },
      "outputs": [],
      "source": [
        "###################### SPARK SETUP ################################\n",
        "#Install findspark\n",
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uetiZ7hS9_C7",
        "outputId": "ad82f48e-9699-459d-f21e-5f4393de922b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: py4j in /usr/local/lib/python3.7/dist-packages (0.10.9.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install py4j"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W97LNBHW-4zO"
      },
      "outputs": [],
      "source": [
        "#Setting up environment variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.0-bin-hadoop3.2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "uLjmc1d--BE5",
        "outputId": "16ad14b8-2ce8-40fa-8c1c-d6c735253434"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://e7f35e93eca6:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.0.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        "
            ],
            "text/plain": [
              "<SparkContext master=local[*] appName=pyspark-shell>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Initialize Spark session using findspark lib\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "sc = spark.sparkContext\n",
        "sc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "weXJ8qyfpVXF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark \n",
        "\n",
        "from pyspark.sql.functions import lit\n",
        "from pyspark.ml.feature import IndexToString\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit,CrossValidator\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.ml import Pipeline, PipelineModel\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7snafWyypcnh"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import functions as f"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrnte6yI-G30"
      },
      "source": [
        "**read the data file**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQHcLDCZ12Le"
      },
      "outputs": [],
      "source": [
        "df = spark.read.csv(path = '/content/book1M/explicit_ratings_books.csv', header = True,inferSchema = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSHz6deo1_yQ",
        "outputId": "0426b182-4601-47a2-a13b-752ecc1cdf1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- userID: integer (nullable = true)\n",
            " |-- ISBN: string (nullable = true)\n",
            " |-- rating: integer (nullable = true)\n",
            " |-- title: string (nullable = true)\n",
            " |-- author: string (nullable = true)\n",
            " |-- yearOfPublication: string (nullable = true)\n",
            " |-- publisher: string (nullable = true)\n",
            " |-- age: string (nullable = true)\n",
            " |-- country: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RI8xvVnU2Fd5",
        "outputId": "d45e121a-345e-4d10-f73a-4c43497f60ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+----------+------+--------------------+----------------+-----------------+--------------------+---+-------------+\n",
            "|userID|      ISBN|rating|               title|          author|yearOfPublication|           publisher|age|      country|\n",
            "+------+----------+------+--------------------+----------------+-----------------+--------------------+---+-------------+\n",
            "|276726|0155061224|     5|    Rites of Passage|      Judith Rae|             2001|              Heinle| 34|          usa|\n",
            "|276729|052165615X|     3|      Help!: Level 1|   Philip Prowse|             1999|Cambridge Univers...| 16|      croatia|\n",
            "|276729|0521795028|     6|The Amsterdam Con...|     Sue Leather|             2001|Cambridge Univers...| 16|      croatia|\n",
            "|276744|038550120X|     7|     A Painted House|    JOHN GRISHAM|             2001|           Doubleday| 34|          usa|\n",
            "|276747|0060517794|     9|Little Altars Eve...|   Rebecca Wells|             2003|         HarperTorch| 25|          usa|\n",
            "|276747|0671537458|     9|   Waiting to Exhale|  Terry McMillan|             1995|              Pocket| 25|          usa|\n",
            "|276747|0679776818|     8|Birdsong: A Novel...|Sebastian Faulks|             1997|   Vintage Books USA| 25|          usa|\n",
            "|276747|0943066433|     7|How to Deal With ...|   Rick Brinkman|             1995|    Careertrack Inc.| 25|          usa|\n",
            "|276747|1885408226|     7|The Golden Rule o...|        Aye Jaye|             1998|Listen &amp; Live...| 25|          usa|\n",
            "|276748|0747558167|     6|Apricots on the N...| Colette Rossant|             2002|Bloomsbury Publis...| 39| saudi arabia|\n",
            "+------+----------+------+--------------------+----------------+-----------------+--------------------+---+-------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.show(10,truncate=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsymeIKd2Zfi",
        "outputId": "70758fe5-b66c-4cd5-9314-b69fe0d7c169"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "383842"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuUJvrDH2cB1",
        "outputId": "16c8c281-8f07-4355-a0cc-5cd00c5de33f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataFrame[summary: string, userID: string, ISBN: string, rating: string, title: string, author: string, yearOfPublication: string, publisher: string, age: string, country: string]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwfatJ8U2iDP"
      },
      "source": [
        "**Collaborative Filtering: Data Modeling using Alternating Least Square matrix (ALS)\n",
        "Select required columns (UserID, ISBN, Ratings)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eDpEpmE2zyi",
        "outputId": "198cda59-b67d-4f99-e198-8204b13aae7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+----------+------+\n",
            "|userID|      ISBN|rating|\n",
            "+------+----------+------+\n",
            "|276726|0155061224|     5|\n",
            "|276729|052165615X|     3|\n",
            "|276729|0521795028|     6|\n",
            "|276744|038550120X|     7|\n",
            "|276747|0060517794|     9|\n",
            "|276747|0671537458|     9|\n",
            "|276747|0679776818|     8|\n",
            "|276747|0943066433|     7|\n",
            "|276747|1885408226|     7|\n",
            "|276748|0747558167|     6|\n",
            "|276751|3596218098|     8|\n",
            "|276754|0684867621|     8|\n",
            "|276755|0451166892|     5|\n",
            "|276762|0380711524|     5|\n",
            "|276762|3453092007|     8|\n",
            "|276772|0553572369|     7|\n",
            "|276772|3499230933|    10|\n",
            "|276772|3596151465|    10|\n",
            "|276774|3442136644|     9|\n",
            "|276786|8437606322|     8|\n",
            "+------+----------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# selecting the columns to work with in the dataset, we do not need all columns for the prediction, only userID, ISBN & rating column \n",
        "data=df.select(df['userID'],df['ISBN'],df['rating'])\n",
        "data.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5achpN224FE",
        "outputId": "d79a1b6c-5c5a-4d2d-b475-c1dffa79652e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+----------+------+------------+----------+\n",
            "|userID|      ISBN|rating|userID_index|ISBN_index|\n",
            "+------+----------+------+------------+----------+\n",
            "|276726|0155061224|     5|     56337.0|   58420.0|\n",
            "|276729|052165615X|     3|     26364.0|   87191.0|\n",
            "|276729|0521795028|     6|     26364.0|   87208.0|\n",
            "|276744|038550120X|     7|     56338.0|     216.0|\n",
            "|276747|0060517794|     9|     12196.0|    1070.0|\n",
            "|276747|0671537458|     9|     12196.0|    2592.0|\n",
            "|276747|0679776818|     8|     12196.0|    1951.0|\n",
            "|276747|0943066433|     7|     12196.0|  124008.0|\n",
            "|276747|1885408226|     7|     12196.0|  137096.0|\n",
            "|276748|0747558167|     6|     56339.0|   42440.0|\n",
            "|276751|3596218098|     8|     56340.0|  145073.0|\n",
            "|276754|0684867621|     8|     56341.0|     374.0|\n",
            "|276755|0451166892|     5|     56342.0|     198.0|\n",
            "|276762|0380711524|     5|     26365.0|    2698.0|\n",
            "|276762|3453092007|     8|     26365.0|   27412.0|\n",
            "|276772|0553572369|     7|     18853.0|    6882.0|\n",
            "|276772|3499230933|    10|     18853.0|   10685.0|\n",
            "|276772|3596151465|    10|     18853.0|   49660.0|\n",
            "|276774|3442136644|     9|     56343.0|   27308.0|\n",
            "|276786|8437606322|     8|     26367.0|   50036.0|\n",
            "+------+----------+------+------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Converting String columns (userID & ISBN) to index\n",
        "s_indexer = [StringIndexer(inputCol=column, outputCol=column+\"_index\") for column in list(set(data.columns)-set(['rating'])) ]\n",
        "pipeline = Pipeline(stages=s_indexer)\n",
        "dftransform = pipeline.fit(data).transform(data)\n",
        "dftransform.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hi_9vvB_Zh0m"
      },
      "source": [
        "Membagi dataset yang sudah dilakukan cleaning ke dalam 2 bagian, Data Training\n",
        "(80%) dan Data Testing (20%)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRO8nPsiAHW7",
        "outputId": "2896e16e-6079-4c42-eb6d-1301eda0d419"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Train dataset: 307153 rows\n",
            "  Test dataset:  76689 rows\n"
          ]
        }
      ],
      "source": [
        "# Randomly split the data into train and test where 80% data is in train and remaining is test\n",
        "train, test = dftransform.randomSplit([0.8, 0.2])\n",
        "print(\"  Train dataset:\", train.count(), \"rows\")\n",
        "print(\"  Test dataset: \", test.count(), \"rows\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_H4bsMJpAMRb"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.recommendation import ALS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7lkvoirAObF"
      },
      "outputs": [],
      "source": [
        "# Build a recommendation model using Alternating Least Squares method\n",
        "# Evaluate the model by computing the RMSE on the test data\n",
        "model = ALS(userCol=\"userID_index\", itemCol=\"ISBN_index\", ratingCol=\"rating\", nonnegative=True, coldStartStrategy=\"drop\").fit(train)\n",
        "\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "evaluator=RegressionEvaluator(metricName=\"rmse\",labelCol=\"rating\",predictionCol=\"prediction\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuhePNMddekp",
        "outputId": "f21aa8a0-5a1f-442b-c543-18c94a56c98d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New RMSE:  2.4802905847663936\n"
          ]
        }
      ],
      "source": [
        "# Make predictions and print the RMSE of the ALS model\n",
        "predictions=model.transform(test)\n",
        "rmse=evaluator.evaluate(predictions)\n",
        "print(\"New RMSE: \", evaluator.evaluate(model.transform(test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyVPtl3rOMvz"
      },
      "source": [
        "***Implementing ALS with Cross Validation***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6otrnE_OOvi"
      },
      "outputs": [],
      "source": [
        "# Import the required functions\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FkLR-uqnOSTZ"
      },
      "outputs": [],
      "source": [
        "# Now we try to improve the performance of the original model using cross validation and solve the cold-start problem.\n",
        "# we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\n",
        "\n",
        "model = ALS(userCol=\"userID_index\", itemCol=\"ISBN_index\", ratingCol=\"rating\", nonnegative = True, coldStartStrategy=\"drop\")\n",
        "\n",
        "#For Parameter tuning of the ALS model we use ParamGridBuilder function\n",
        "#We tune two parameters \n",
        "#1. The Regularization parameter ranging from 0.1, 0.01, 0.001, 0.0001\n",
        "#2. The rank for matrix factorization\n",
        "paramGrid = ParamGridBuilder() \\\n",
        "    .addGrid(model.regParam, [0.1, 0.05, 0.01, 0.001]) \\\n",
        "    .addGrid(model.rank, [5, 10, 20, 30]) \\\n",
        "    .build()\n",
        "\n",
        "#Defining a cross-validator object\n",
        "#Setting up CV and adding parameters. We will be performing a 5 fold CV\n",
        "crossvalidation = CrossValidator(estimator = model,\n",
        "                     estimatorParamMaps = paramGrid,\n",
        "                     evaluator = evaluator,\n",
        "                     numFolds=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwf_045E-Ev1"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Build cross validation using CrossValidator\n",
        "cv = CrossValidator(estimator=model, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rodUDRw7FZp9"
      },
      "outputs": [],
      "source": [
        "#Fit cross validator to the 'train' dataset\n",
        "model = crossvalidation.fit(train)\n",
        "\n",
        "#Extract best model from the cv model above\n",
        "best_model = model.bestModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfehHt6dO82C"
      },
      "source": [
        "***Printing the Best Model's parameter values***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "REBX5-M0PBRj"
      },
      "outputs": [],
      "source": [
        "#The Best_model\n",
        "print(type(best_model))\n",
        "#Complete the code below to extract the ALS model parameters\n",
        "print(\"**Best Model**\")\n",
        "#Rank\n",
        "print(\"Rank: \", best_model._java_obj.parent().getRank())\n",
        "#MaxIter\n",
        "print(\"MaxIter: \", best_model._java_obj.parent().getMaxIter())\n",
        "#RegParam\n",
        "print(\"RegParam: \", best_model._java_obj.parent().getRegParam())\n",
        "# Calculate the RMSE on test data using the best set of parameters obtained after cross validation\n",
        "print(\"Best RMSE value is: \", evaluator.evaluate(best_model.transform(test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGqyplx69y9v"
      },
      "outputs": [],
      "source": [
        "# Define evaluator as RMSE and print length of evaluator\n",
        "evaluator = RegressionEvaluator(\n",
        "           metricName=\"rmse\", \n",
        "           labelCol=\"rating\", \n",
        "           predictionCol=\"prediction\") \n",
        "print (\"Num models to be tested: \", len(paramGrid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tw4jLrxLSwPN"
      },
      "outputs": [],
      "source": [
        "pred = best_model.transform(test)\n",
        "pred.show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Va8FFS5jS2F2",
        "outputId": "bb047b4e-b835-4c49-d752-57f64e89ef9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+--------------------+------+----------+\n",
            "|userId|               title|genres|prediction|\n",
            "+------+--------------------+------+----------+\n",
            "|   597|Hudsucker Proxy, ...|Comedy|  4.671783|\n",
            "|   602|Hudsucker Proxy, ...|Comedy| 3.5895188|\n",
            "|   409|Hudsucker Proxy, ...|Comedy| 3.9152715|\n",
            "|   610|Hudsucker Proxy, ...|Comedy|  3.603048|\n",
            "|   217|Hudsucker Proxy, ...|Comedy| 2.7374995|\n",
            "+------+--------------------+------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "pred.join(Movies, \"movieId\").select(\"userId\",\"title\",\"genres\",\"prediction\").show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3MVEPh3ErvH"
      },
      "source": [
        "***Data Sparsity and Cold Start***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmZ5NdIGEjA4",
        "outputId": "60e3c508-51a2-4207-ab4b-9ab4081345eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The ratings dataframe is  99.82% sparse.\n"
          ]
        }
      ],
      "source": [
        "def get_mat_sparsity(ratings):\n",
        "    # Count the total number of ratings in the dataset\n",
        "    count_nonzero = ratings.select(\"rating\").count()\n",
        "\n",
        "    # Count the number of distinct userIds and distinct movieIds\n",
        "    total_elements = ratings.select(\"userId\").distinct().count() * ratings.select(\"movieId\").distinct().count()\n",
        "\n",
        "    # Divide the numerator by the denominator\n",
        "    sparsity = (1.0 - (count_nonzero *1.0)/total_elements)*100\n",
        "    print(\"The ratings dataframe is \", \"%.2f\" % sparsity + \"% sparse.\")\n",
        "    \n",
        "get_mat_sparsity(ratings)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ALS-Bookcrossing",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}